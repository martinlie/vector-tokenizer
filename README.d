# GPT-2

We will build a GPT-2 language model for predicting the next token in a sequence of time series vectors. 


### References:
- [1] [LLM from scratch using jax](https://github.com/ChristianOrr/transformers)


## Installation

```
python -m venv .venv
.venv/Scripts/activate
python -m pip install -r requirements.txt
```
